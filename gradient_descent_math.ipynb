{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Quick Review: Gradient Descent\n",
    "\n",
    "In order to be able to evaluate if our gradient descent algorithm is working\n",
    "correctly, we will need to be able to calculate the cost.\n",
    "\n",
    "Recall the log likelihood function for logistic regression. Our goal is to *maximize* this value.\n",
    "\n",
    "![Cost Function](images/likelihood.png)\n",
    "<!--\n",
    "\\ell(\\boldsymbol\\beta) = \\sum_{i=1}^{n} y_i \\log ( h(\\mathbf{x_i}) ) + (1-y_i) \\log (1 - h(\\mathbf{x_i}))\n",
    "-->\n",
    "\n",
    "Recall that the hypothesis function *h* is defined as follows:\n",
    "\n",
    "![hypothesis](images/hypothesis.png)\n",
    "<!--\n",
    "h(\\mathbf{x_i}) = \\frac{1}{1+e^{-\\boldsymbol\\beta\\mathbf{x_i}}}\n",
    "-->\n",
    "\n",
    "Since we will be implemented Gradient *Descent*, which *minimizes* a function, we'll look at the cost function below, which is just the negation of the log likelihood function above.\n",
    "\n",
    "![cost function](images/cost.png)\n",
    "<!--\n",
    "J(\\boldsymbol\\beta) = - \\sum_{i=1}^{n} y_i \\log ( h(\\mathbf{x_i}) ) + (1-y_i) \\log (1 - h(\\mathbf{x_i}))\n",
    "-->\n",
    "\n",
    "The gradient of the cost function is as follows:\n",
    "\n",
    "![gradient](images/gradient.png)\n",
    "<!--\n",
    "\\nabla J(\\boldsymbol\\beta) =\n",
    "\\left[\n",
    "\\frac\\partial{\\partial\\beta_1}J(\\boldsymbol\\beta),\n",
    "\\frac\\partial{\\partial\\beta_2}J(\\boldsymbol\\beta),\n",
    "\\ldots,\n",
    "\\frac\\partial{\\partial\\beta_p}J(\\boldsymbol\\beta)\n",
    "\\right]\n",
    "-->\n",
    "\n",
    "Each partial derivative will be computed as follows:\n",
    "\n",
    "![partial](images/partial.png)\n",
    "<!--\n",
    "\\frac\\partial{\\partial\\beta_j}J(\\boldsymbol\\beta) =\n",
    "\\sum_{i=1}^n \\left( h(\\mathbf{x_i}) - y_i \\right ) x_{ij}\n",
    "-->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Derivative of the sigmoid function: \n",
    "\n",
    "![hypothesis](images/sigmoid_derivative.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
